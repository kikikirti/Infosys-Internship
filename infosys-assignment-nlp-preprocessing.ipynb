{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"qp9Nbc1UuGY2","cell_type":"markdown","source":"# NLP Text Preprocessing Notebook\nThis notebook covers:\n- Text Cleaning\n- Tokenization\n- Stopwords\n- Stemming & Lemmatization\n- N-grams\n- Basic Frequency Analysis\n","metadata":{"id":"qp9Nbc1UuGY2"}},{"id":"ObzX0t-kuGY6","cell_type":"code","source":"import nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk.util import ngrams\nfrom collections import Counter\n\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"id":"ObzX0t-kuGY6","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:03:36.672942Z","iopub.execute_input":"2025-12-09T11:03:36.673354Z","iopub.status.idle":"2025-12-09T11:05:12.713754Z","shell.execute_reply.started":"2025-12-09T11:03:36.673328Z","shell.execute_reply":"2025-12-09T11:05:12.712649Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":2},{"id":"gH9ZiCC1uGY9","cell_type":"code","source":"text = \"Hello!!! This is NLP Class 2025. Learn Text Preprocessing @Google Meet. :)\"\ncleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\ncleaned_text = cleaned_text.lower().strip()\ncleaned_text","metadata":{"id":"gH9ZiCC1uGY9","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:05:12.715574Z","iopub.execute_input":"2025-12-09T11:05:12.716128Z","iopub.status.idle":"2025-12-09T11:05:12.722271Z","shell.execute_reply.started":"2025-12-09T11:05:12.716095Z","shell.execute_reply":"2025-12-09T11:05:12.721324Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'hello this is nlp class  learn text preprocessing google meet'"},"metadata":{}}],"execution_count":3},{"id":"ow74PXhVuGY-","cell_type":"code","source":"from nltk.tokenize import word_tokenize\ntokens = word_tokenize(cleaned_text)\ntokens","metadata":{"id":"ow74PXhVuGY-","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:05:12.723132Z","iopub.execute_input":"2025-12-09T11:05:12.723428Z","iopub.status.idle":"2025-12-09T11:05:12.774610Z","shell.execute_reply.started":"2025-12-09T11:05:12.723407Z","shell.execute_reply":"2025-12-09T11:05:12.773715Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['hello',\n 'this',\n 'is',\n 'nlp',\n 'class',\n 'learn',\n 'text',\n 'preprocessing',\n 'google',\n 'meet']"},"metadata":{}}],"execution_count":4},{"id":"HPI2MY5guGY-","cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nfiltered_tokens = [word for word in tokens if word not in stop_words]\nfiltered_tokens","metadata":{"id":"HPI2MY5guGY-","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:05:12.775499Z","iopub.execute_input":"2025-12-09T11:05:12.775762Z","iopub.status.idle":"2025-12-09T11:05:12.786315Z","shell.execute_reply.started":"2025-12-09T11:05:12.775740Z","shell.execute_reply":"2025-12-09T11:05:12.785538Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['hello', 'nlp', 'class', 'learn', 'text', 'preprocessing', 'google', 'meet']"},"metadata":{}}],"execution_count":5},{"id":"tLqy5qMluGY-","cell_type":"code","source":"ps = PorterStemmer()\nstemmed = [ps.stem(word) for word in filtered_tokens]\nstemmed","metadata":{"id":"tLqy5qMluGY-","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:05:12.788872Z","iopub.execute_input":"2025-12-09T11:05:12.789121Z","iopub.status.idle":"2025-12-09T11:05:12.799774Z","shell.execute_reply.started":"2025-12-09T11:05:12.789102Z","shell.execute_reply":"2025-12-09T11:05:12.798979Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['hello', 'nlp', 'class', 'learn', 'text', 'preprocess', 'googl', 'meet']"},"metadata":{}}],"execution_count":6},{"id":"GdR46CiiuGY_","cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\nlemmatized = [lemmatizer.lemmatize(word) for word in filtered_tokens]\nlemmatized","metadata":{"id":"GdR46CiiuGY_","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:05:12.800689Z","iopub.execute_input":"2025-12-09T11:05:12.800942Z","iopub.status.idle":"2025-12-09T11:05:16.264607Z","shell.execute_reply.started":"2025-12-09T11:05:12.800920Z","shell.execute_reply":"2025-12-09T11:05:16.263649Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['hello', 'nlp', 'class', 'learn', 'text', 'preprocessing', 'google', 'meet']"},"metadata":{}}],"execution_count":7},{"id":"48z-U-3AuGY_","cell_type":"code","source":"bigrams = list(ngrams(tokens, 2))\ntrigrams = list(ngrams(tokens, 3))\nbigrams, trigrams","metadata":{"id":"48z-U-3AuGY_","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:05:16.265654Z","iopub.execute_input":"2025-12-09T11:05:16.266008Z","iopub.status.idle":"2025-12-09T11:05:16.273880Z","shell.execute_reply.started":"2025-12-09T11:05:16.265972Z","shell.execute_reply":"2025-12-09T11:05:16.272893Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"([('hello', 'this'),\n  ('this', 'is'),\n  ('is', 'nlp'),\n  ('nlp', 'class'),\n  ('class', 'learn'),\n  ('learn', 'text'),\n  ('text', 'preprocessing'),\n  ('preprocessing', 'google'),\n  ('google', 'meet')],\n [('hello', 'this', 'is'),\n  ('this', 'is', 'nlp'),\n  ('is', 'nlp', 'class'),\n  ('nlp', 'class', 'learn'),\n  ('class', 'learn', 'text'),\n  ('learn', 'text', 'preprocessing'),\n  ('text', 'preprocessing', 'google'),\n  ('preprocessing', 'google', 'meet')])"},"metadata":{}}],"execution_count":8},{"id":"ShlR6D7SuGZA","cell_type":"code","source":"Counter(tokens)","metadata":{"id":"ShlR6D7SuGZA","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:05:16.275131Z","iopub.execute_input":"2025-12-09T11:05:16.275497Z","iopub.status.idle":"2025-12-09T11:05:16.299001Z","shell.execute_reply.started":"2025-12-09T11:05:16.275467Z","shell.execute_reply":"2025-12-09T11:05:16.298107Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Counter({'hello': 1,\n         'this': 1,\n         'is': 1,\n         'nlp': 1,\n         'class': 1,\n         'learn': 1,\n         'text': 1,\n         'preprocessing': 1,\n         'google': 1,\n         'meet': 1})"},"metadata":{}}],"execution_count":9},{"id":"5JtUvI0hkIVm","cell_type":"code","source":"!pip install gensim","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JtUvI0hkIVm","outputId":"000c371b-8e78-40a4-bed8-528886278fd0","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:05:16.300069Z","iopub.execute_input":"2025-12-09T11:05:16.300427Z","iopub.status.idle":"2025-12-09T11:05:21.886910Z","shell.execute_reply.started":"2025-12-09T11:05:16.300400Z","shell.execute_reply":"2025-12-09T11:05:21.885597Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.4.0)\nRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\nRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.15.3)\nRequirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (2.4.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open>=1.8.1->gensim) (1.17.2)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->gensim) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->gensim) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->gensim) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.5->gensim) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.5->gensim) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.5->gensim) (2024.2.0)\n","output_type":"stream"}],"execution_count":10},{"id":"9wmGiMJ6j8tD","cell_type":"code","source":"# Imports & sample data =====\nimport numpy as np\nimport pandas as pd\n\n# Scikit-learn\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, roc_auc_score, confusion_matrix\n\n# Optional for Word2Vec\n# pip install gensim\nfrom gensim.models import Word2Vec\n\n# Optional for sentence embeddings\n# pip install sentence-transformers\n# from sentence_transformers import SentenceTransformer\n\n# For saving\nimport joblib\n\n# Sample small dataset (binary sentiment)\ndata = {\n    \"text\": [\n        \"I love this product, it is amazing and works great\",\n        \"Terrible service, I will never buy again\",\n        \"Really enjoyed the experience, very satisfied\",\n        \"The product broke within days, worst purchase ever\",\n        \"Delicious food and quick delivery\",\n        \"Not worth the money, extremely disappointed\"\n    ],\n    \"label\": [1, 0, 1, 0, 1, 0]  # 1 -> positive, 0 -> negative\n}\ndf = pd.DataFrame(data)\ndf\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"9wmGiMJ6j8tD","outputId":"30a7634c-d6d5-4bf1-fcfa-2308d2f34e41","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:05:21.888211Z","iopub.execute_input":"2025-12-09T11:05:21.888511Z","iopub.status.idle":"2025-12-09T11:06:05.000704Z","shell.execute_reply.started":"2025-12-09T11:05:21.888483Z","shell.execute_reply":"2025-12-09T11:06:04.999791Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  I love this product, it is amazing and works g...      1\n1           Terrible service, I will never buy again      0\n2      Really enjoyed the experience, very satisfied      1\n3  The product broke within days, worst purchase ...      0\n4                  Delicious food and quick delivery      1\n5        Not worth the money, extremely disappointed      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I love this product, it is amazing and works g...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Terrible service, I will never buy again</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Really enjoyed the experience, very satisfied</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The product broke within days, worst purchase ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Delicious food and quick delivery</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Not worth the money, extremely disappointed</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"id":"V4Vr6D87kO7J","cell_type":"code","source":"# BoW and TF-IDF examples =====\ntexts = df['text'].tolist()\n\n# Bag of Words\ncv = CountVectorizer(ngram_range=(1,1), min_df=1)\nX_bow = cv.fit_transform(texts)\nprint(\"BoW features shape:\", X_bow.shape)\nprint(\"BoW feature names:\", cv.get_feature_names_out())\n\n# TF-IDF\ntfidf = TfidfVectorizer(ngram_range=(1,2), min_df=1)  # unigrams + bigrams\nX_tfidf = tfidf.fit_transform(texts)\nprint(\"TF-IDF features shape:\", X_tfidf.shape)\nprint(\"Example TF-IDF feature names (first 20):\", tfidf.get_feature_names_out()[:20])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4Vr6D87kO7J","outputId":"e2157cc1-0b8f-4b0c-8e3d-86049c0e083f","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:05.001711Z","iopub.execute_input":"2025-12-09T11:06:05.002249Z","iopub.status.idle":"2025-12-09T11:06:05.034833Z","shell.execute_reply.started":"2025-12-09T11:06:05.002219Z","shell.execute_reply":"2025-12-09T11:06:05.033309Z"}},"outputs":[{"name":"stdout","text":"BoW features shape: (6, 36)\nBoW feature names: ['again' 'amazing' 'and' 'broke' 'buy' 'days' 'delicious' 'delivery'\n 'disappointed' 'enjoyed' 'ever' 'experience' 'extremely' 'food' 'great'\n 'is' 'it' 'love' 'money' 'never' 'not' 'product' 'purchase' 'quick'\n 'really' 'satisfied' 'service' 'terrible' 'the' 'this' 'very' 'will'\n 'within' 'works' 'worst' 'worth']\nTF-IDF features shape: (6, 70)\nExample TF-IDF feature names (first 20): ['again' 'amazing' 'amazing and' 'and' 'and quick' 'and works' 'broke'\n 'broke within' 'buy' 'buy again' 'days' 'days worst' 'delicious'\n 'delicious food' 'delivery' 'disappointed' 'enjoyed' 'enjoyed the' 'ever'\n 'experience']\n","output_type":"stream"}],"execution_count":12},{"id":"VtzBUlu6kW-u","cell_type":"code","source":"# Word2Vec demo =====\n# Tokenize sentences simply (after your preprocessing pipeline)\ntokenized = [t.lower().split() for t in texts]\nw2v_model = Word2Vec(sentences=tokenized, vector_size=50, window=5, min_count=1, workers=1, seed=42)\n\n# Get embedding for a word\nprint(\"Vector for 'product' (shape):\", w2v_model.wv['product'].shape)\n\n# To get sentence embedding: average word vectors (simple)\ndef sentence_vector(sentence, model):\n    toks = sentence.lower().split()\n    vecs = [model.wv[w] for w in toks if w in model.wv]\n    if len(vecs)==0:\n        return np.zeros(model.vector_size)\n    return np.mean(vecs, axis=0)\n\nsent_emb = np.vstack([sentence_vector(s, w2v_model) for s in texts])\nprint(\"Sentence embeddings shape:\", sent_emb.shape)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VtzBUlu6kW-u","outputId":"74350d3c-2016-4a1a-9739-8ad594385019","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:05.036311Z","iopub.execute_input":"2025-12-09T11:06:05.037032Z","iopub.status.idle":"2025-12-09T11:06:05.080987Z","shell.execute_reply.started":"2025-12-09T11:06:05.036992Z","shell.execute_reply":"2025-12-09T11:06:05.079651Z"}},"outputs":[{"name":"stdout","text":"Vector for 'product' (shape): (50,)\nSentence embeddings shape: (6, 50)\n","output_type":"stream"}],"execution_count":13},{"id":"vLXSKzjNkau2","cell_type":"code","source":"# Train-test split (use TF-IDF features) =====\nX = X_tfidf\ny = df['label'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\nprint(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vLXSKzjNkau2","outputId":"de5616ad-cdd3-4cda-8fd6-12e6b3329143","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:05.082348Z","iopub.execute_input":"2025-12-09T11:06:05.082811Z","iopub.status.idle":"2025-12-09T11:06:05.095776Z","shell.execute_reply.started":"2025-12-09T11:06:05.082780Z","shell.execute_reply":"2025-12-09T11:06:05.094466Z"}},"outputs":[{"name":"stdout","text":"Train: (4, 70) Test: (2, 70)\n","output_type":"stream"}],"execution_count":14},{"id":"RUTRGC40kbc1","cell_type":"code","source":"# Train baseline models =====\nmodels = {\n    \"NaiveBayes\": MultinomialNB(),\n    \"LogisticRegression\": LogisticRegression(max_iter=1000, solver='liblinear'),\n    \"LinearSVC\": LinearSVC(max_iter=10000)\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    acc = accuracy_score(y_test, preds)\n    print(f\"{name} -> Accuracy: {acc:.3f}\")\n    print(classification_report(y_test, preds))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RUTRGC40kbc1","outputId":"2c74b3cc-e696-4b84-8b5d-b46b9f7e1f55","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:05.098799Z","iopub.execute_input":"2025-12-09T11:06:05.099071Z","iopub.status.idle":"2025-12-09T11:06:05.144154Z","shell.execute_reply.started":"2025-12-09T11:06:05.099051Z","shell.execute_reply":"2025-12-09T11:06:05.143138Z"}},"outputs":[{"name":"stdout","text":"NaiveBayes -> Accuracy: 0.500\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.50      1.00      0.67         1\n\n    accuracy                           0.50         2\n   macro avg       0.25      0.50      0.33         2\nweighted avg       0.25      0.50      0.33         2\n\nLogisticRegression -> Accuracy: 0.500\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.50      1.00      0.67         1\n\n    accuracy                           0.50         2\n   macro avg       0.25      0.50      0.33         2\nweighted avg       0.25      0.50      0.33         2\n\nLinearSVC -> Accuracy: 0.500\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.50      1.00      0.67         1\n\n    accuracy                           0.50         2\n   macro avg       0.25      0.50      0.33         2\nweighted avg       0.25      0.50      0.33         2\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":15},{"id":"5rmPwV6gkeZC","cell_type":"code","source":"# Evaluation utilities =====\ndef evaluate_model(model, X_test, y_test):\n    if hasattr(model, \"predict_proba\"):\n        probs = model.predict_proba(X_test)[:,1]\n    else:\n        # fallback: use decision_function if available and scale to [0,1]\n        if hasattr(model, \"decision_function\"):\n            from sklearn.preprocessing import MinMaxScaler\n            scores = model.decision_function(X_test).reshape(-1,1)\n            probs = MinMaxScaler().fit_transform(scores).ravel()\n        else:\n            probs = None\n\n    preds = model.predict(X_test)\n    acc = accuracy_score(y_test, preds)\n    p, r, f1, _ = precision_recall_fscore_support(y_test, preds, average='binary', zero_division=0)\n    print(\"Accuracy:\", acc)\n    print(\"Precision:\", p, \"Recall:\", r, \"F1:\", f1)\n    if probs is not None:\n        try:\n            print(\"ROC-AUC:\", roc_auc_score(y_test, probs))\n        except:\n            pass\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n    print(\"---- Detailed report ----\")\n    print(classification_report(y_test, preds))\n\n# Example run on the logistic regression model\nevaluate_model(models['LogisticRegression'], X_test, y_test)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rmPwV6gkeZC","outputId":"0e233d69-0d0a-4c3e-f7b5-5ff96b6fa1a3","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:05.145238Z","iopub.execute_input":"2025-12-09T11:06:05.145584Z","iopub.status.idle":"2025-12-09T11:06:05.172229Z","shell.execute_reply.started":"2025-12-09T11:06:05.145551Z","shell.execute_reply":"2025-12-09T11:06:05.171138Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.5\nPrecision: 0.5 Recall: 1.0 F1: 0.6666666666666666\nROC-AUC: 1.0\nConfusion Matrix:\n [[0 1]\n [0 1]]\n---- Detailed report ----\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.50      1.00      0.67         1\n\n    accuracy                           0.50         2\n   macro avg       0.25      0.50      0.33         2\nweighted avg       0.25      0.50      0.33         2\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":16},{"id":"qtoVvaSZki93","cell_type":"code","source":"# Pipeline + GridSearch =====\npipeline = Pipeline([\n    ('tfidf', TfidfVectorizer()),\n    ('clf', LogisticRegression(solver='liblinear', max_iter=1000))\n])\n\nparam_grid = {\n    'tfidf__ngram_range': [(1,1), (1,2)],\n    'tfidf__min_df': [1, 2],\n    'clf__C': [0.1, 1, 10]\n}\n\ngs = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1', n_jobs=-1)\ngs.fit(df['text'], df['label'])\nprint(\"Best params:\", gs.best_params_)\nprint(\"Best CV score:\", gs.best_score_)\n\n# Evaluate best model on holdout (we'll split again)\nX_train2, X_test2, y_train2, y_test2 = train_test_split(df['text'], df['label'], test_size=0.33, random_state=42, stratify=df['label'])\nbest_model = gs.best_estimator_\nbest_model.fit(X_train2, y_train2)\npreds = best_model.predict(X_test2)\nprint(classification_report(y_test2, preds))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtoVvaSZki93","outputId":"859958d3-dc30-4981-9d96-093291149574","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:05.173234Z","iopub.execute_input":"2025-12-09T11:06:05.173501Z","iopub.status.idle":"2025-12-09T11:06:07.341635Z","shell.execute_reply.started":"2025-12-09T11:06:05.173473Z","shell.execute_reply":"2025-12-09T11:06:07.340568Z"}},"outputs":[{"name":"stdout","text":"Best params: {'clf__C': 0.1, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1)}\nBest CV score: 0.4444444444444444\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.50      1.00      0.67         1\n\n    accuracy                           0.50         2\n   macro avg       0.25      0.50      0.33         2\nweighted avg       0.25      0.50      0.33         2\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":17},{"id":"SavBmIdOkrGs","cell_type":"markdown","source":"Try ngram_range=(1,2) or (1,3) for capturing phrases.\n\nUse stopword removal when vocabulary is noisy.\n\nUse character n-grams for short text (reviews, tweets).\n\nLimit max_features or use min_df to control vocabulary size.\n\nHashingVectorizer for memory-efficient transform on large corpora.\n\nCombine TF-IDF with pretrained sentence embeddings for hybrid features (concatenate dense + sparse)","metadata":{"id":"SavBmIdOkrGs"}},{"id":"IYb7iZ9VkmvQ","cell_type":"code","source":"\n# !pip install sentence-transformers\n# from sentence_transformers import SentenceTransformer\n# s_model = SentenceTransformer('all-MiniLM-L6-v2')  # example model\n# sentence_embeddings = s_model.encode(df['text'].tolist(), show_progress_bar=True)\n# print(\"Embeddings shape:\", sentence_embeddings.shape)\n","metadata":{"id":"IYb7iZ9VkmvQ","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:07.342905Z","iopub.execute_input":"2025-12-09T11:06:07.343257Z","iopub.status.idle":"2025-12-09T11:06:07.348380Z","shell.execute_reply.started":"2025-12-09T11:06:07.343227Z","shell.execute_reply":"2025-12-09T11:06:07.346930Z"}},"outputs":[],"execution_count":18},{"id":"FeySzGt0kz4O","cell_type":"code","source":"# =====  Save & load pipeline =====\n# Example: save best_model from GridSearch\njoblib.dump(best_model, \"best_text_pipeline.joblib\")\n# Load\nloaded = joblib.load(\"best_text_pipeline.joblib\")\n# Inference\nsample = [\"I really hate the support and the product quality\"]\nprint(\"Prediction:\", loaded.predict(sample))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FeySzGt0kz4O","outputId":"1afb0665-f2d7-4d98-9f4b-6eeb1e807b0c","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:07.349352Z","iopub.execute_input":"2025-12-09T11:06:07.349743Z","iopub.status.idle":"2025-12-09T11:06:07.380203Z","shell.execute_reply.started":"2025-12-09T11:06:07.349714Z","shell.execute_reply":"2025-12-09T11:06:07.378842Z"}},"outputs":[{"name":"stdout","text":"Prediction: [1]\n","output_type":"stream"}],"execution_count":19},{"id":"_FWK1DmKk9qQ","cell_type":"markdown","source":"Inference pipeline (production notes) (cell: markdown)\n\nPipeline should include preprocessing → vectorization → model. Save it as a single Pipeline object (as above).\n\nEnsure same text cleaning/normalization used at train time is applied during inference.\n\nFor scaling to production: wrap pipeline in a small API (FastAPI/Flask) and serve with Gunicorn/Uvicorn + container (Docker).\n\nIf model needs to be retrained periodically, automate dataset collection, validation, and CI tests.","metadata":{"id":"_FWK1DmKk9qQ"}},{"id":"FwAMfd0plQR6","cell_type":"markdown","source":"**Short assignment / exercises t**\nCompare performances: CountVectorizer vs TfidfVectorizer vs Word2Vec averaged embeddings on a 10k-sample dataset.\n\nTry ngram_range=(1,3) and observe overfitting/feature explosion.\n\nUse GridSearchCV to tune C for Logistic Regression and alpha for MultinomialNB.\n\n(Create an inference API using FastAPI that loads best_text_pipeline.joblib and exposes POST /predict.\nDon't create an api just save the image)\n(Advanced) Fine-tune a small transformer (e.g., DistilBERT) for sentiment classification using Hugging Face **transformers**","metadata":{"id":"FwAMfd0plQR6"}},{"id":"lcCP1CX4lEnL","cell_type":"code","source":"# Compare CV vs TF-IDF vs Word2Vec (Logistic Regression)\n\nfrom sklearn.metrics import f1_score\n\ndef simple_lr_experiment(X_feat, y_labels, description):\n    X_tr, X_te, y_tr, y_te = train_test_split(\n        X_feat, y_labels,\n        test_size=0.33,\n        random_state=42,\n        stratify=y_labels\n    )\n    lr = LogisticRegression(max_iter=1000, solver='liblinear')\n    lr.fit(X_tr, y_tr)\n    preds = lr.predict(X_te)\n    acc = accuracy_score(y_te, preds)\n    f1 = f1_score(y_te, preds, zero_division=0)\n   \n    print(\"Accuracy:\", acc)\n    print(\"F1-score:\", f1)\n    print(classification_report(y_te, preds, zero_division=0))\n\n\ncv2 = CountVectorizer()\nX_cv2 = cv2.fit_transform(df[\"text\"])\nsimple_lr_experiment(X_cv2, df[\"label\"].values, \"CountVectorizer + LogisticRegression\")\n\ntfidf2 = TfidfVectorizer()\nX_tfidf2 = tfidf2.fit_transform(df[\"text\"])\nsimple_lr_experiment(X_tfidf2, df[\"label\"].values, \"TF-IDF + LogisticRegression\")\n\n\nX_w2v = sent_emb   \nsimple_lr_experiment(X_w2v, df[\"label\"].values, \"Word2Vec averaged + LogisticRegression\")\n","metadata":{"id":"lcCP1CX4lEnL","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:07.381720Z","iopub.execute_input":"2025-12-09T11:06:07.382079Z","iopub.status.idle":"2025-12-09T11:06:07.429688Z","shell.execute_reply.started":"2025-12-09T11:06:07.382044Z","shell.execute_reply":"2025-12-09T11:06:07.428677Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.5\nF1-score: 0.6666666666666666\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.50      1.00      0.67         1\n\n    accuracy                           0.50         2\n   macro avg       0.25      0.50      0.33         2\nweighted avg       0.25      0.50      0.33         2\n\nAccuracy: 0.5\nF1-score: 0.6666666666666666\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.50      1.00      0.67         1\n\n    accuracy                           0.50         2\n   macro avg       0.25      0.50      0.33         2\nweighted avg       0.25      0.50      0.33         2\n\nAccuracy: 0.5\nF1-score: 0.0\n              precision    recall  f1-score   support\n\n           0       0.50      1.00      0.67         1\n           1       0.00      0.00      0.00         1\n\n    accuracy                           0.50         2\n   macro avg       0.25      0.50      0.33         2\nweighted avg       0.25      0.50      0.33         2\n\n","output_type":"stream"}],"execution_count":20},{"id":"696afc70-0dff-4b31-8ea7-65d1a428f02b","cell_type":"code","source":"# Try ngram_range = (1,3) in TF-IDF\n\ntfidf_1_3 = TfidfVectorizer(ngram_range=(1, 3), min_df=1)\nX_tfidf_1_3 = tfidf_1_3.fit_transform(df[\"text\"])\n\nprint(\"TF-IDF (1,3) shape:\", X_tfidf_1_3.shape)\nprint(\"First 30 feature names (1,3):\")\nprint(tfidf_1_3.get_feature_names_out()[:30])\n\nsimple_lr_experiment(X_tfidf_1_3, df[\"label\"].values, \"TF-IDF (1,3) + LogisticRegression\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:07.430733Z","iopub.execute_input":"2025-12-09T11:06:07.431043Z","iopub.status.idle":"2025-12-09T11:06:07.452495Z","shell.execute_reply.started":"2025-12-09T11:06:07.431019Z","shell.execute_reply":"2025-12-09T11:06:07.451266Z"}},"outputs":[{"name":"stdout","text":"TF-IDF (1,3) shape: (6, 98)\nFirst 30 feature names (1,3):\n['again' 'amazing' 'amazing and' 'amazing and works' 'and' 'and quick'\n 'and quick delivery' 'and works' 'and works great' 'broke' 'broke within'\n 'broke within days' 'buy' 'buy again' 'days' 'days worst'\n 'days worst purchase' 'delicious' 'delicious food' 'delicious food and'\n 'delivery' 'disappointed' 'enjoyed' 'enjoyed the'\n 'enjoyed the experience' 'ever' 'experience' 'experience very'\n 'experience very satisfied' 'extremely']\nAccuracy: 0.5\nF1-score: 0.6666666666666666\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.50      1.00      0.67         1\n\n    accuracy                           0.50         2\n   macro avg       0.25      0.50      0.33         2\nweighted avg       0.25      0.50      0.33         2\n\n","output_type":"stream"}],"execution_count":21},{"id":"805ce0a7-f385-4faf-9ce3-437630949ca4","cell_type":"code","source":"# GridSearch for LogisticRegression (C) and NaiveBayes (alpha)\n\nlog_pipeline = Pipeline([\n    ('tfidf', TfidfVectorizer()),\n    ('clf', LogisticRegression(solver='liblinear', max_iter=1000))\n])\n\nlog_param_grid = {\n    'tfidf__ngram_range': [(1, 1)],\n    'clf__C': [0.01, 0.1, 1, 10]\n}\n\nlog_gs = GridSearchCV(\n    log_pipeline,\n    log_param_grid,\n    cv=3,\n    scoring='f1',\n    n_jobs=-1\n)\nlog_gs.fit(df[\"text\"], df[\"label\"])\nprint(\"Best LogisticRegression params:\", log_gs.best_params_)\nprint(\"Best LogisticRegression CV F1:\", log_gs.best_score_)\n\nnb_pipeline = Pipeline([\n    ('tfidf', TfidfVectorizer()),\n    ('clf', MultinomialNB())\n])\n\nnb_param_grid = {\n    'tfidf__ngram_range': [(1, 1)],\n    'clf__alpha': [0.1, 0.5, 1.0, 2.0]\n}\n\nnb_gs = GridSearchCV(\n    nb_pipeline,\n    nb_param_grid,\n    cv=3,\n    scoring='f1',\n    n_jobs=-1\n)\nnb_gs.fit(df[\"text\"], df[\"label\"])\nprint(\"Best MultinomialNB params:\", nb_gs.best_params_)\nprint(\"Best MultinomialNB CV F1:\", nb_gs.best_score_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:06:07.453446Z","iopub.execute_input":"2025-12-09T11:06:07.453698Z","iopub.status.idle":"2025-12-09T11:06:07.583485Z","shell.execute_reply.started":"2025-12-09T11:06:07.453677Z","shell.execute_reply":"2025-12-09T11:06:07.582412Z"}},"outputs":[{"name":"stdout","text":"Best LogisticRegression params: {'clf__C': 0.01, 'tfidf__ngram_range': (1, 1)}\nBest LogisticRegression CV F1: 0.4444444444444444\nBest MultinomialNB params: {'clf__alpha': 0.1, 'tfidf__ngram_range': (1, 1)}\nBest MultinomialNB CV F1: 0.5555555555555555\n","output_type":"stream"}],"execution_count":22},{"id":"a876f94a-e111-4ec4-a6d5-29f61f4af279","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}